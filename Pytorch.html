<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>5. PyTorch Models &mdash; FitSNAP  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6. Uncertainty Quantification" href="Uncertainty%20Quantification.html" />
    <link rel="prev" title="4. Linear Models" href="Linear.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> FitSNAP
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Introduction.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="Installation.html">2. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="Run.html">3. Run FitSNAP</a></li>
<li class="toctree-l1"><a class="reference internal" href="Linear.html">4. Linear Models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">5. PyTorch Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#getting-started">5.1. Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fitting-neural-network-potentials">5.2. Fitting Neural Network Potentials</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loss-function">5.3. Loss Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="#outputs-and-error-calculation">5.4. Outputs and Error Calculation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#error-comparison-files">5.4.1. Error/Comparison files</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pytorch-model-files">5.4.2. PyTorch model files</a></li>
<li class="toctree-l3"><a class="reference internal" href="#calculate-errors-on-a-test-set">5.4.3. Calculate errors on a test set</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#training-performance">5.5. Training Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#gpu-acceleration">5.5.1. GPU Acceleration</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Uncertainty%20Quantification.html">6. Uncertainty Quantification</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Programmer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Contributing.html">1. Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="Executable.html">2. Executable</a></li>
<li class="toctree-l1"><a class="reference internal" href="Library.html">3. Library</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">FitSNAP</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active"><span class="section-number">5. </span>PyTorch Models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Pytorch.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="pytorch-models">
<h1><span class="section-number">5. </span>PyTorch Models<a class="headerlink" href="#pytorch-models" title="Permalink to this heading"></a></h1>
<p>Interfacing with PyTorch allows us to conveniently fit neural network potentials using descriptors
that exist in LAMMPS. We may then use these neural network models to run high-performance MD
simulations in LAMMPS. These capabilities are explained below.</p>
<section id="getting-started">
<h2><span class="section-number">5.1. </span>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this heading"></a></h2>
<p>First we need a python environment with PyTorch and LAMMPS installed. See <a class="reference external" href="Installation.html#lammps-installation">LAMMPS Installation docs</a>
for more details on installing LAMMPS. Here we start with a speedy minimal description LAMMPS setup:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span># Create and activate a new conda environment

conda create --name fitsnap python=3.10
conda activate fitsnap

# Install dependencies with your conda&#39;s pip

python -m pip install numpy torch scipy virtualenv psutil pandas tabulate mpi4py Cython

# Clone the LAMMPS repo

git clone https://github.com/lammps/lammps

# Make a LAMMPS build specifically for FitSNAP

LAMMPS_DIR=/path/to/lammps
mkdir $LAMMPS_DIR/build-fitsnap
cd $LAMMPS_DIR/build-fitsnap
cmake ../cmake -DLAMMPS_EXCEPTIONS=yes \
               -DBUILD_SHARED_LIBS=yes \
               -DMLIAP_ENABLE_PYTHON=yes \
               -DPKG_PYTHON=yes \
               -DPKG_ML-SNAP=yes \
               -DPKG_ML-IAP=yes \
               -DPKG_ML-PACE=yes \
               -DPKG_SPIN=yes \
               -DPYTHON_EXECUTABLE:FILEPATH=`which python`
make
make install-python
</pre></div>
</div>
<p>To add these extra <code class="code docutils literal notranslate"><span class="pre">-D</span></code> flags in <code class="code docutils literal notranslate"><span class="pre">ccmake</span></code>, go to the Advanced Options section in
<code class="code docutils literal notranslate"><span class="pre">ccmake</span></code>.</p>
<p>Set the following environment variables so that your Python can find LAMMPS:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>LAMMPS_DIR=/path/to/lammps
export LD_LIBRARY_PATH=$LAMMPS_DIR/build-fitsnap:$LD_LIBRARY_PATH # Use DYLD_LIBRARY_PATH for MacOS
export PYTHONPATH=$LAMMPS_DIR/python:$PYTHONPATH
</pre></div>
</div>
<p>Alternatively to setting environment variables, symbolic links to these paths are also appropriate.</p>
<p><strong>Before proceeding, make sure your LAMMPS-Python interface is working</strong> by doing the following in
your Python interpreter:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">lammps</span>
<span class="n">lmp</span> <span class="o">=</span> <span class="n">lammps</span><span class="o">.</span><span class="n">lammps</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>If this gives no errors, proceed further. Otherwise, please take more time to install LAMMPS with
Python properly on your system.</strong> See <a class="reference external" href="Installation.html#lammps-installation">LAMMPS Installation docs</a>
for more info.</p>
<p>Get FitSNAP with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">where</span><span class="o">/</span><span class="n">FitSNAP</span><span class="o">/</span><span class="n">will</span><span class="o">/</span><span class="n">be</span>
<span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">FitSNAP</span><span class="o">/</span><span class="n">FitSNAP</span>
</pre></div>
</div>
<p>Fit a neural network for tantalum:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>FITSNAP_DIR=/path/to/FitSNAP
export PYTHONPATH=$FITSNAP_DIR:$PYTHONPATH # So you can run FitSNAP as executable
cd $FITSNAP_DIR/examples/Ta_PyTorch_NN
python -m fitsnap3 Ta-example.in --overwrite
</pre></div>
</div>
<p>Run high-performance MD with this neural network potential:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>SITE_PACKAGES_DIR=`python -c &quot;import site; print(site.getsitepackages()[0])&quot;`
export PYTHONPATH=${SITE_PACKAGES_DIR}:$PYTHONPATH # So that ML-IAP package can find torch for MD
cd MD
mpirun -np 4 ${LAMMPS_DIR}/fitsnap-build/lmp &lt; in.run
</pre></div>
</div>
<p>More details on setting up input scripts for NN fitting are given below. If you want instructions on
getting set up with a cluster, please see <a class="reference external" href="Quick.html">Quick Instructions</a>.</p>
</section>
<section id="fitting-neural-network-potentials">
<h2><span class="section-number">5.2. </span>Fitting Neural Network Potentials<a class="headerlink" href="#fitting-neural-network-potentials" title="Permalink to this heading"></a></h2>
<p>Similarly to how we fit linear models, we can input descriptors into nonlinear models such as
neural networks. To do this, we can use the same FitSNAP input script that we use for linear
models, with some slight changes to the sections. First we must add a <code class="code docutils literal notranslate"><span class="pre">PYTORCH</span></code> section,
which for the tantalum example looks like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">PYTORCH</span><span class="p">]</span>
<span class="n">layer_sizes</span> <span class="o">=</span>  <span class="n">num_desc</span> <span class="mi">60</span> <span class="mi">60</span> <span class="mi">1</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1.5e-4</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">save_state_output</span> <span class="o">=</span> <span class="n">Ta_Pytorch</span><span class="o">.</span><span class="n">pt</span>
<span class="n">energy_weight</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">force_weight</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">training_fraction</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">multi_element_option</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>We must also add a <code class="code docutils literal notranslate"><span class="pre">nonlinear</span> <span class="pre">=</span> <span class="pre">1</span></code> key in the <code class="code docutils literal notranslate"><span class="pre">CALCULATOR</span></code> section, and set
<code class="code docutils literal notranslate"><span class="pre">solver</span> <span class="pre">=</span> <span class="pre">PYTORCH</span></code> in the <code class="code docutils literal notranslate"><span class="pre">SOLVER</span></code> section. Now the input script is ready to fit a
neural network potential.</p>
<p>The <code class="code docutils literal notranslate"><span class="pre">PYTORCH</span></code> section keys are explained in more detail below.</p>
<ul>
<li><p><code class="code docutils literal notranslate"><span class="pre">layer_sizes</span></code> determines the network architecture. We lead with a <code class="code docutils literal notranslate"><span class="pre">num_desc</span></code> parameter
which tells FitSNAP that the number of nodes in the first layer are equal to the number of
descriptors. The argument here is a list where each element determines the number of nodes in
each layer.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">learning_rate</span></code> determines how fast the network minimizes the loss function. We find that
a learning rate around <code class="code docutils literal notranslate"><span class="pre">1e-4</span></code> works well when fitting to forces, and when using our current
loss function.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">num_epochs</span></code> sets the number of gradient descent iterations.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">batch_size</span></code> determines how many configs to average gradients for when looping over batches
in a single epoch. We find that a batch size around 4 works well for our models.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">save_state_output</span></code> is the name of the PyTorch model file to write after every
epoch. This model can be loaded for testing purposes later.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">save_state_input</span></code> is the name of a PyTorch model that may be loaded for the purpose of
restarting an existing fit, or for calculating test errors.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">energy_weight</span></code> is a scalar constant multiplied by the mean squared energy error in the
loss function. Declaring this parameter will override the weights in the GROUPS section for all
configs. We therefore call this the <em>global energy weight</em>. If you want to specify energy weights
for each group, do so in the GROUPS section.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">force_weight</span></code> is a scalar constant multiplied by the mean squared force error in the loss
function. Declaring this parameter will override the weights in the GROUPS section for all
configs. We therefore call this the <em>global force weight</em>. If you want to specify force weights
for each group, do so in the GROUPS section.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">training_fraction</span></code> is a decimal fraction of how much of the total data should be trained
on. The leftover <code class="code docutils literal notranslate"><span class="pre">1.0</span> <span class="pre">-</span> <span class="pre">training_fraction</span></code> portion is used for calculating validation errors
during a fit. Declaring this parameter will override the training/testing fractions in the GROUPS
section for all configs. We therefore call this the <em>global training fraction</em>. If you want to
specify training/testing fractions for each group, do so in the GROUPS section.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">multi_element_option</span></code> is a scalar that determines how to handle multiple element types.</p>
<blockquote>
<div><ul class="simple">
<li><p>1: All element types share the same network. Descriptors may still be different per type.</p></li>
<li><p>2: Each element type has its own network.</p></li>
<li><p>3: (Coming soon) One-hot encoding of element types, where each type shares the same network.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><code class="code docutils literal notranslate"><span class="pre">manual_seed_flag</span></code> set to 0 by default, can set to 1 if want to force a random seed which is
useful for debugging purposes.</p></li>
</ul>
</section>
<section id="loss-function">
<h2><span class="section-number">5.3. </span>Loss Function<a class="headerlink" href="#loss-function" title="Permalink to this heading"></a></h2>
<p>When fitting neural network potentials we minimize the sum of weighted energy and force mean squared
errors:</p>
<div class="math notranslate nohighlight">
\[\mathcal L = \frac{1}{M} \sum_{m}^{M} \frac{1}{N_m}\{w_m^E [\hat{E}_m(\theta) - E_m]^2 + \frac{w_m^F}{3} \sum_i^{3N_m} [\hat{F}_{mi}(\theta) - F_{mi}]^2 \}\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(M\)</span> is the number of configurations in the training set.</p></li>
<li><p><span class="math notranslate nohighlight">\(m\)</span> indexes a particular configuration.</p></li>
<li><p><span class="math notranslate nohighlight">\(N_m\)</span> is the number of atoms for configuration <span class="math notranslate nohighlight">\(m\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(w_m^E\)</span> is the energy weight of configuration <span class="math notranslate nohighlight">\(m\)</span>. These weights can be set by designating
the particular weights in the <a class="reference external" href="Run.html#groups">[GROUPS] section</a>, or by declaring a global
weight in the <code class="code docutils literal notranslate"><span class="pre">[PYTORCH]</span></code> section, which will override the group weights.</p></li>
<li><p><span class="math notranslate nohighlight">\(\theta\)</span> represents all the model fitting parameters (e.g. the trainable coefficients in a neural network).</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{E}_m(\theta)\)</span> is the model predicted energy of configuration <span class="math notranslate nohighlight">\(m\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(E_m\)</span> is the target <em>ab initio</em> energy of configuration <span class="math notranslate nohighlight">\(m\)</span>, subtracted by the LAMMPS
reference potential declared in the <a class="reference external" href="Run.html#reference">[REFERENCE] section</a>.</p></li>
<li><p><span class="math notranslate nohighlight">\(i\)</span> indexes a Cartesian index of a single atom; we lump Cartesian indices and atom indices
into a single index here.</p></li>
<li><p><span class="math notranslate nohighlight">\(w_m^F\)</span> is the force weight of configuration <span class="math notranslate nohighlight">\(m\)</span>. These weights can be set by designating
the particular weights in the <a class="reference external" href="Run.html#groups">[GROUPS] section</a>, or by declaring a global
weight in the <code class="code docutils literal notranslate"><span class="pre">[PYTORCH]</span></code> section, which will override the group weights.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{F}_{mi}(\theta)\)</span> is a model predicted force component <span class="math notranslate nohighlight">\(i\)</span> in configuration <span class="math notranslate nohighlight">\(m\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(F_{mi}\)</span> is a target <em>ab initio</em> force component <span class="math notranslate nohighlight">\(i\)</span> in configuration <span class="math notranslate nohighlight">\(m\)</span>,
subtracted by the LAMMPS reference potential force declared in the
<a class="reference external" href="Run.html#reference">[REFERENCE] section</a>.</p></li>
</ul>
<p>This loss also gets evaluated for the validation set for each epoch, so that the screen output looks
something like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-----</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">0</span>
<span class="n">Batch</span> <span class="n">averaged</span> <span class="n">train</span><span class="o">/</span><span class="n">val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">4.002996124327183</span> <span class="mf">4.072216800280979</span>
<span class="n">Epoch</span> <span class="n">time</span> <span class="mf">0.3022959232330322</span>
<span class="o">-----</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span>
<span class="n">Batch</span> <span class="n">averaged</span> <span class="n">train</span><span class="o">/</span><span class="n">val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">2.3298445120453835</span> <span class="mf">1.1800143867731094</span>
<span class="n">Epoch</span> <span class="n">time</span> <span class="mf">0.2888479232788086</span>
<span class="o">-----</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">2</span>
<span class="n">Batch</span> <span class="n">averaged</span> <span class="n">train</span><span class="o">/</span><span class="n">val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.6962545616552234</span> <span class="mf">0.8775447851845196</span>
<span class="n">Epoch</span> <span class="n">time</span> <span class="mf">0.26888108253479004</span>
<span class="o">-----</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">3</span>
<span class="n">Batch</span> <span class="n">averaged</span> <span class="n">train</span><span class="o">/</span><span class="n">val</span> <span class="n">loss</span><span class="p">:</span> <span class="mf">0.3671231440966949</span> <span class="mf">0.6234593641545091</span>
<span class="n">Epoch</span> <span class="n">time</span> <span class="mf">0.26917600631713867</span>
</pre></div>
</div>
<p>The first column is the weighted training set loss function, and the second column is the weighted
validation set loss function (which is not included in fitting). While the loss function units
themselves might not be meaningful for error analysis, we output model predictions and targets for
energies and forces in separate files after the fit, as explained below.</p>
</section>
<section id="outputs-and-error-calculation">
<h2><span class="section-number">5.4. </span>Outputs and Error Calculation<a class="headerlink" href="#outputs-and-error-calculation" title="Permalink to this heading"></a></h2>
<p>Unlike linear models, PyTorch models do not output statistics in a dataframe. Instead we output
energy and force comparisons in separate files, along with PyTorch models that can be used to restart
a fit or even run MD simulations in LAMMPS.</p>
<section id="error-comparison-files">
<h3><span class="section-number">5.4.1. </span>Error/Comparison files<a class="headerlink" href="#error-comparison-files" title="Permalink to this heading"></a></h3>
<p>After training a potential, FitSNAP produces outputs that can be used to intrepret the quality of a
fit on the training and/or validation data. The following comparison files are written after a fit:</p>
<ul class="simple">
<li><p><code class="code docutils literal notranslate"><span class="pre">energy_comparison.dat</span></code> energy comparisons for all configs in the training set. Each row
corresponds to a specific configuration in the training set. The first column is the model energy,
and the 2nd column is the target energy.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">energy_comparison_val.dat</span></code> energy comparisons for all configs in the validation set.
Format is same as above.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">force_comparison.dat</span></code> force comparisons for all atoms in all configs in the training set.
Each row corresponds to a single atom’s Cartesian component for a specific config in the training
set. The first column is the model energy, and the 2nd column is the target energy.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">force_comparison_val.dat</span></code> same as above, but for the validation set.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">loss_vs_epochs.dat</span></code> training and validation loss as a function of epochs, to check convergence.</p></li>
</ul>
<p>These outputs allow you to compare the configuration energies, or per-atom forces, however you want
after a fit. For example, in the <a class="reference external" href="https://github.com/FitSNAP/FitSNAP/tree/master/examples/Ta_PyTorch_NN">Ta_PyTorch_NN example</a>
, we provide python scripts that help post-process these files to calculate mean absolute error or
plot comparisons in energies and forces.</p>
</section>
<section id="pytorch-model-files">
<h3><span class="section-number">5.4.2. </span>PyTorch model files<a class="headerlink" href="#pytorch-model-files" title="Permalink to this heading"></a></h3>
<p>FitSNAP outputs two PyTorch <code class="code docutils literal notranslate"><span class="pre">.pt</span></code> models file after fitting. One is used for restarting a fit
based on an existing model, specifically the model name supplied by the user in the
<code class="code docutils literal notranslate"><span class="pre">save_state_output</span></code> keyword of the input script. In the <a class="reference external" href="https://github.com/FitSNAP/FitSNAP/tree/master/examples/Ta_PyTorch_NN">Ta_PyTorch_NN example</a>
we can see this keyword is <code class="code docutils literal notranslate"><span class="pre">Ta_Pytorch.pt</span></code>. This file will therefore be saved every epoch, and
it may be fed into FitSNAP via the <code class="code docutils literal notranslate"><span class="pre">save_state_input</span></code> keyword to restart another fit from that
particular model.</p>
<p>The other PyTorch model is used for running MD simulations in LAMMPS after a fit. This file has the
name <code class="code docutils literal notranslate"><span class="pre">FitTorch_Pytorch.pt</span></code>, and is used to run MD in LAMMPS via the ML-IAP package. An example
is given for tantalum here: <a class="reference external" href="https://github.com/FitSNAP/FitSNAP/tree/master/examples/Ta_PyTorch_NN/MD">https://github.com/FitSNAP/FitSNAP/tree/master/examples/Ta_PyTorch_NN/MD</a></p>
</section>
<section id="calculate-errors-on-a-test-set">
<h3><span class="section-number">5.4.3. </span>Calculate errors on a test set<a class="headerlink" href="#calculate-errors-on-a-test-set" title="Permalink to this heading"></a></h3>
<p>Users may want to use models to calculate errors on a test set that was completely separate from the
training/validation sets used in fitting. To do this, we change the input script to read an existing
PyTorch model file, e.g. for Ta:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">PYTORCH</span><span class="p">]</span>
<span class="n">layer_sizes</span> <span class="o">=</span>  <span class="n">num_desc</span> <span class="mi">60</span> <span class="mi">60</span> <span class="mi">1</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1.5e-4</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1">##### Set to 1 for calculating test errors</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">save_state_input</span> <span class="o">=</span> <span class="n">Ta_Pytorch</span><span class="o">.</span><span class="n">pt</span> <span class="c1">##### Load an existing model</span>
<span class="n">energy_weight</span> <span class="o">=</span> <span class="mf">1e-2</span>
<span class="n">force_weight</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">training_fraction</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">multi_element_option</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">num_elements</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>Notice how we are now using <code class="code docutils literal notranslate"><span class="pre">save_state_input</span></code> instead of <code class="code docutils literal notranslate"><span class="pre">save_state_output</span></code>, and that
we set <code class="code docutils literal notranslate"><span class="pre">num_epochs</span> <span class="pre">=</span> <span class="pre">1</span></code>. This will load the existing PyTorch model, and perform a single epoch
which involves calculating the energy and force comparisons (mentioned above) for the current model,
on whatever user-defined groups of configs in the groups section.We can therefore use the energy and
force comparison files here to calculate mean absolute errors, e.g. with the script in
the <a class="reference external" href="https://github.com/FitSNAP/FitSNAP/tree/master/examples/Ta_PyTorch_NN">Ta_PyTorch_NN example</a></p>
</section>
</section>
<section id="training-performance">
<h2><span class="section-number">5.5. </span>Training Performance<a class="headerlink" href="#training-performance" title="Permalink to this heading"></a></h2>
<p>As seen in the <code class="code docutils literal notranslate"><span class="pre">Ta_Pytorch_NN</span></code> example, fitting to ~300 configs (each with ~12 atoms) takes
about ~0.2 s/epoch. The number of epochs required, and therefore total time of your fit, will depend
on the size of your dataset <em>and</em> the <code class="code docutils literal notranslate"><span class="pre">batch_size</span></code>. For example, the <code class="code docutils literal notranslate"><span class="pre">Ta_Pytorch_NN</span></code> example
might take ~200 epochs to fully converge (see <code class="code docutils literal notranslate"><span class="pre">loss_vs_epochs.dat</span></code>). In this example, however,
we used <code class="code docutils literal notranslate"><span class="pre">batch_size=4</span></code>, meaning that each epoch involved <code class="code docutils literal notranslate"><span class="pre">~300/4</span> <span class="pre">=</span> <span class="pre">~75</span></code> gradient descent
minimizations as we cycled through batches. For much larger datasets, the network will experience
more cycles through the batches with each epoch, and therefore may require less epochs to reach
the same convergence.</p>
<p>For data sets of ~10,000 configs and ~50 atoms per config, training will take ~1 hour, or about
20 seconds per epoch. This can consume about ~20 GB of RAM.</p>
<p>Computational scaling is roughly <code class="code docutils literal notranslate"><span class="pre">O(num_atoms*num_neighs)</span></code> where <code class="code docutils literal notranslate"><span class="pre">num_atoms</span></code> is the
total number of atoms in the training set, and <code class="code docutils literal notranslate"><span class="pre">num_neighs</span></code> is the average number of neighbors
per atom.</p>
<p>Mini-batch network training is embarassingly parallel up to the batch size, but currently FitSNAP
does not support parallelized NN training.</p>
<section id="gpu-acceleration">
<h3><span class="section-number">5.5.1. </span>GPU Acceleration<a class="headerlink" href="#gpu-acceleration" title="Permalink to this heading"></a></h3>
<p>FitSNAP supports GPU acceleration via PyTorch. With small batch sizes, however, most of the benefit
of GPU parallelization comes from evaluating the NN model and calculating gradients. You will not see
a large benefit of GPUs using a small batch size unless you have a large NN model (e.g. &gt; 1 million
parameters). If you have a small model, you will see a speedup on GPUs using a large enough batch
size.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Linear.html" class="btn btn-neutral float-left" title="4. Linear Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="Uncertainty%20Quantification.html" class="btn btn-neutral float-right" title="6. Uncertainty Quantification" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Sandia Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>